#!/usr/bin/env python

import os, sys, argparse, glob
import subprocess as sub
from multiprocessing import Pool, cpu_count, Process

# for clocking processes
import time

sys.path.append('common')
import utils

class getMean:
  def __init__(self, inPDF, outDir, pgMean=43):
    """
    See doc in main().

    Input
      inPDF -- str, path of PDF from which mean plot is extracted
      outDir -- str, directory into which mean plot is written
      pgMean -- int, should be 43 since we have 42 Garand profiles and
        plot the mean after all of the individual profiles
    """

    if not os.path.exists(outDir): os.makedirs(outDir)

    self.allProfs = inPDF
    self.outPDF = '%s/mean_%s' % (outDir, os.path.basename(inPDF))
    self.pageMean = pgMean
  # end constructor

  def gs(self):
    """
    Summon GhostScript for PDF page extraction

    https://www.linuxjournal.com/content/tech-tip-extract-pages-pdf
    """

    # not entirely sure what all of the arguments do, but this works
    # (it was suggested in the Linux Journal link) so i'm 
    # going with it all
    args = ['gs', '-sDEVICE=pdfwrite', \
      '-dNOPAUSE', '-dBATCH', '-dSAFER', \
      '-dFirstPage=%d' % self.pageMean, \
      '-dLastPage=%d' % self.pageMean, \
      '-sOutputFile=%s' % self.outPDF, self.allProfs]
    t1 = time.clock()
    sub.call(args)
    print(time.clock()-t1)
    print('Wrote %s' % self.outPDF)
  # end gs
# end getMean()

def poolMean(inObj):
  """
  Simple function that runs the gs() method for a single getMean()
  object (but this function should be used in multithreading)
  """

  inObj.gs()
# end poolMean

if __name__ == '__main__':
  parser = argparse.ArgumentParser(\
    description='Call GhostScript on all of the PDF files ' + \
    'generated by parallel_e2e.py so we can just grab the last ' + \
    'page (the mean test-ref flux and HR differences over all ' + \
    'Garand profiles.')
  parser.add_argument('--indir', '-i', type=str, \
    default='profile_plots/linear', \
    help='Directory with PDFs that contain complete profile plots' + \
    '(individual + mean).')
  parser.add_argument('--outdir', '-o', type=str, \
    default='profile_plots/mean_linear', \
    help='Directory into which mean PDF files are written.')
  parser.add_argument('--cores', '-c', type=int, default=6, \
    help='Number of cores over which to process')
  args = parser.parse_args()

  # find all PDFs to "convert"
  allPDF = sorted(glob.glob('%s/*.pdf' % args.indir))
  nPDF = len(allPDF)
  if nPDF == 0: sys.exit('Found no PDFs to process')

  # create an object for each PDF
  allObj = []
  for pdf in allPDF: allObj.append(getMean(pdf, args.outdir))

  # split the gs() method over many cores
  nCores = args.cores
  totCores = cpu_count()
  nCores = nCores if nCores < totCores else totCores-1

  p = Pool(nCores)
  pMean = p.map(poolMean, allObj)
# end main()
